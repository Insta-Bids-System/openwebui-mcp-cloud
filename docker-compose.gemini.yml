version: '3.9'

# Docker Compose with Gemini Support Enabled
# Usage: docker-compose -f docker-compose.gemini.yml up -d

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui-dev
    ports:
      - "8080:8080"
    environment:
      - ENABLE_COMMUNITY_SHARING=false
      - ENABLE_MESSAGE_RATING=true
    volumes:
      - ./data/openwebui:/app/backend/data
    networks:
      - dev-net

  mcp-server:
    build: ./mcp-server
    container_name: mcp-server-dev
    environment:
      - OPENWEBUI_URL=http://open-webui:8080
    volumes:
      - ./data/workspace:/workspace
    networks:
      - dev-net

  mcpo-openwebui:
    image: ghcr.io/open-webui/mcpo:main
    container_name: mcpo-openwebui-dev
    ports:
      - "8101:8000"
    command: ["mcpo", "--host", "0.0.0.0", "--port", "8000", "--", "python", "/workspace/main.py"]
    environment:
      - PYTHONPATH=/workspace
    volumes:
      - ./mcp-server:/workspace
    depends_on:
      - mcp-server
    networks:
      - dev-net

  # Gemini API Support via LiteLLM
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    ports:
      - "4000:4000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY:-YOUR_GEMINI_API_KEY_HERE}
    command: |
      --model gemini/gemini-pro
      --model gemini/gemini-pro-vision
      --model gemini/gemini-1.5-pro
      --model gemini/gemini-1.5-flash
      --port 4000
    networks:
      - dev-net

networks:
  dev-net:
    driver: bridge